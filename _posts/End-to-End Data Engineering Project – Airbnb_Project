---

title: "End-to-End Data Engineering Project ‚Äì Airbnb_Project"
date: 2025-01-12
categories: [Data Engineering, Cloud, Snowflake, AWS]
tags: [Data Engineering, Snowflake, AWS, S3, dbt, SQL, Python, Analytics Engineering]

---

## üè® End-to-End Data Engineering Project ‚Äì Airbnb_Project

![Airbnb End-to-End](./assets/images/Airbnb.png)

En este proyecto dise√±√© e implement√© una **arquitectura end-to-end de ingenier√≠a de datos**, simulando un escenario real de **log√≠stica y entregas de √∫ltima milla**, con un enfoque claro en **escalabilidad, calidad de datos y anal√≠tica avanzada**.

El objetivo principal fue transformar **datos crudos** en **datasets confiables, gobernados y listos para consumo**, aplicando **buenas pr√°cticas modernas de Data Engineering y Analytics Engineering**.

---

## üéØ Problema de negocio

Las operaciones de **√∫ltima milla** generan grandes vol√∫menes de datos provenientes de m√∫ltiples fuentes, lo que suele ocasionar problemas como:

- Datos distribuidos en **CSV, Excel, SQL y m√∫ltiples sistemas**
- Errores en **fechas, horas, IDs y relaciones**
- Dificultad para escalar el an√°lisis cuando el volumen crece
- Dependencia de procesos manuales para preparar informaci√≥n
- Falta de una **fuente √∫nica de la verdad (Single Source of Truth)**

En este escenario, el negocio necesita:
- Analizar desempe√±o operativo
- Preparar datos para **BI (Power BI)** y **Machine Learning**
- Escalar sin redise√±ar la arquitectura cada vez que crecen los datos

---

## üìä Escalabilidad y volumen de datos

Durante el dise√±o estim√© un volumen aproximado de **5 TB de datos hist√≥ricos**, considerando:

- Eventos de entregas
- Reservas / pedidos
- Informaci√≥n de clientes, ubicaciones y hosts
- Crecimiento continuo en el tiempo

Por esta raz√≥n, la soluci√≥n se dise√±√≥ desde el inicio para:
- Soportar **grandes vol√∫menes**
- Separar **almacenamiento y c√≥mputo**
- Permitir **escalado horizontal**
- Mantener costos controlados

---

## üèóÔ∏è Arquitectura utilizada

La arquitectura sigue un enfoque **Lakehouse + Analytics Engineering**, combinando lo mejor de Data Lakes y Data Warehouses.

![Arquitectura Lakehouse](./assets/images/amazon_lakehouse_flow.png)

### Flujo general

1. **Amazon S3** como Data Lake
2. **Snowflake** como motor anal√≠tico
3. **dbt (Antigravity)** para transformaci√≥n y modelado
4. Capas Bronze ‚Üí Staging ‚Üí Marts
5. Datos listos para **Power BI y Machine Learning**

---

## üß∞ Stack tecnol√≥gico

- **Amazon S3** ‚Üí Data Lake / Source of Truth  
- **Snowflake** ‚Üí Data Warehouse escalable  
- **dbt (Antigravity)** ‚Üí Transformaciones, tests y documentaci√≥n  
- **SQL** ‚Üí L√≥gica de negocio  
- **Python** ‚Üí Preparaci√≥n y automatizaci√≥n  
- **GitHub** ‚Üí Control de versiones  
- **Power BI / ML** ‚Üí Consumo final de datos  

---

## üîÑ Flujo de datos detallado

### 1Ô∏è‚É£ Data Lake ‚Äì Amazon S3

- Almacena los datos **en bruto**
- No se modifica la informaci√≥n original
- Funciona como **fuente √∫nica de la verdad**
- Permite reprocesar datos hist√≥ricos sin p√©rdida

---

### 2Ô∏è‚É£ Snowflake ‚Äì Capa Bronze

- Ingesta directa desde S3
- Datos **tal como llegan**
- Sin reglas de negocio complejas
- Garantiza trazabilidad y auditor√≠a

Ejemplo:
- `bronze_bookings`
- `bronze_hosts`
- `bronze_listings`

---

### 3Ô∏è‚É£ Snowflake ‚Äì Capa Staging (dbt)

- Limpieza y estandarizaci√≥n
- Normalizaci√≥n de nombres y tipos de datos
- Preparaci√≥n para an√°lisis

Ejemplos:
- `stg_bookings`
- `stg_hosts`
- `stg_listings`

---

### 4Ô∏è‚É£ Snowflake ‚Äì Capa Marts (dbt)

- Modelado anal√≠tico
- Esquema estrella
- Optimizado para BI y ML

Tablas finales:
- `dim_hosts`
- `dim_listings`
- `fct_bookings`

---

## üß† Reglas de negocio implementadas con dbt

- Validaciones `not_null` y `unique`
- Tests de relaciones entre dimensiones y hechos
- Separaci√≥n clara de responsabilidades por capa
- Transformaciones versionadas y documentadas
- Re-ejecuci√≥n confiable del pipeline

Esto garantiza:
- **Calidad de datos**
- **Confianza del negocio**
- **Menos errores en dashboards y modelos**

---

## üìà Consumo de datos

Los datos finales quedan listos para:

- **Power BI** ‚Üí dashboards operativos y estrat√©gicos
- **Equipos de Machine Learning** ‚Üí feature engineering
- **Analistas** ‚Üí consultas r√°pidas y confiables
- **Stakeholders** ‚Üí toma de decisiones basada en datos

---

## ‚úÖ Conclusiones

- Se construy√≥ un pipeline **end-to-end realista y escalable**
- La arquitectura soporta **grandes vol√∫menes de datos**
- dbt permiti√≥ gobernar y validar la l√≥gica de negocio
- Snowflake aport√≥ flexibilidad y performance
- El dise√±o est√° preparado para crecer sin refactorizar

---

## üîç Reflexi√≥n final

Este proyecto refleja c√≥mo un **Data Engineer moderno** no solo mueve datos, sino que **dise√±a sistemas confiables, escalables y orientados al negocio**.

La combinaci√≥n de **Data Lake + Snowflake + dbt** permite construir plataformas de datos preparadas para el futuro, donde **Analytics y Machine Learning** pueden convivir sobre una misma base s√≥lida.

Este enfoque es totalmente aplicable a escenarios reales de **log√≠stica, retail, supply chain y operaciones a gran escala**.

---

üöÄ *Proyecto desarrollado como parte de mi portafolio profesional en Data Engineering.*
